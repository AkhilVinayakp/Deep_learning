{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TimeSeries.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoFnbpTdIxJRwkd0gp3NZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhilVinayakp/Deep_learning/blob/main/TimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTncvtQMHq0Z"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I5Sj1uPCHxer",
        "outputId": "49a83a3a-19d4-4926-8bc4-610487eed496"
      },
      "source": [
        "# additional installation\r\n",
        "!pip install -U tf-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/dc/2bdc73a88a3661fdea62242e7e074e3e2b600f01543ce24751a48d486ad5/tf_nightly-2.5.0.dev20210304-cp37-cp37m-manylinux2010_x86_64.whl (410.0MB)\n",
            "\u001b[K     |████████████████████████████████| 410.0MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting tb-nightly~=2.5.0.a\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/f4/72947db77318db93ac0d29ff02509c33cf4686784c4a2832e89724591694/tb_nightly-2.5.0a20210304-py3-none-any.whl (6.1MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1MB 43.8MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly~=2.5.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/14/85df3bc812c6dedcacacb17d8dc53a5155a554b577b4e2c5b6665bc6feb1/tf_estimator_nightly-2.5.0.dev2021030401-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.10.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/d1/f38a91d8724706427fe973a7dfa11e938cee98aa7196b03d870a25a08bab/grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.0.1)\n",
            "Collecting tensorboard-data-server<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6f/a1a04f6aece9cdabe80fba01241e76172380753801e34ad50d482fbde0c0/tensorboard_data_server-0.3.0-py3-none-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.27.0)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: grpcio, tensorboard-data-server, tb-nightly, tf-estimator-nightly, cached-property, h5py, gast, tf-nightly\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 tb-nightly-2.5.0a20210304 tensorboard-data-server-0.3.0 tf-estimator-nightly-2.5.0.dev2021030401 tf-nightly-2.5.0.dev20210304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "h5py",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcc8ujMeID0u",
        "outputId": "c8feeafa-086f-46e0-a385-cbeee4502ff8"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mpu6A38IMDf"
      },
      "source": [
        "def plot_time_data(time, series, format=\"-\", start = 0, end = None, label = None):\r\n",
        "  \"\"\"plot a time series data\"\"\"\r\n",
        "  plt.plot(time[start:end], series[start:end], format, label)\r\n",
        "  plt.xlabel(\"time\")\r\n",
        "  plt.ylabel(\"Values\")\r\n",
        "  if label:\r\n",
        "    plt.legend()\r\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKXbHHBLKArW"
      },
      "source": [
        "# testing data windowing\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykBPUW_46EF6"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyWciZ5t6I-2"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDLFmE4w6Qfm",
        "outputId": "77f9455a-295c-40a4-b526-e253b08f4422"
      },
      "source": [
        "for val in dataset:\r\n",
        "  print(val.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMDNvQay6Rvv"
      },
      "source": [
        "# windowing \r\n",
        "dataset = dataset.window(4,shift=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw2UNYAK65v9",
        "outputId": "482a4e62-2ef6-4bd5-9755-c942a4e26b63"
      },
      "source": [
        "for window_data in dataset:\r\n",
        "  print(\"Windowed data\")\r\n",
        "  for val in window_data:\r\n",
        "    print(val.numpy(), end = ' ')\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Windowed data\n",
            "0 1 2 3 \n",
            "Windowed data\n",
            "2 3 4 5 \n",
            "Windowed data\n",
            "4 5 6 7 \n",
            "Windowed data\n",
            "6 7 8 9 \n",
            "Windowed data\n",
            "8 9 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHVnfDTM6-ol",
        "outputId": "f129d83e-e7a0-4b7b-9028-c90859baa34f"
      },
      "source": [
        "# regularly sized windows\r\n",
        "dataset = tf.data.Dataset.range(40)\r\n",
        "dataset = dataset.window(6,shift=3, drop_remainder=True)\r\n",
        "for window_data in dataset:\r\n",
        "  print(\"Windowed data\")\r\n",
        "  for val in window_data:\r\n",
        "    print(val.numpy(), end = ' ')\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Windowed data\n",
            "0 1 2 3 4 5 \n",
            "Windowed data\n",
            "3 4 5 6 7 8 \n",
            "Windowed data\n",
            "6 7 8 9 10 11 \n",
            "Windowed data\n",
            "9 10 11 12 13 14 \n",
            "Windowed data\n",
            "12 13 14 15 16 17 \n",
            "Windowed data\n",
            "15 16 17 18 19 20 \n",
            "Windowed data\n",
            "18 19 20 21 22 23 \n",
            "Windowed data\n",
            "21 22 23 24 25 26 \n",
            "Windowed data\n",
            "24 25 26 27 28 29 \n",
            "Windowed data\n",
            "27 28 29 30 31 32 \n",
            "Windowed data\n",
            "30 31 32 33 34 35 \n",
            "Windowed data\n",
            "33 34 35 36 37 38 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWn_nWdM8ZLj",
        "outputId": "0f6524b9-b8cb-4321-8013-f6895dae8e7a"
      },
      "source": [
        "# creating the numpylist for the window\r\n",
        "# regularly sized windows\r\n",
        "dataset = tf.data.Dataset.range(40)\r\n",
        "dataset = dataset.window(6,shift=3, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda window : window.batch(6))\r\n",
        "for window in dataset:\r\n",
        "  print(\"window data\")\r\n",
        "  print(window.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "window data\n",
            "[0 1 2 3 4 5]\n",
            "window data\n",
            "[3 4 5 6 7 8]\n",
            "window data\n",
            "[ 6  7  8  9 10 11]\n",
            "window data\n",
            "[ 9 10 11 12 13 14]\n",
            "window data\n",
            "[12 13 14 15 16 17]\n",
            "window data\n",
            "[15 16 17 18 19 20]\n",
            "window data\n",
            "[18 19 20 21 22 23]\n",
            "window data\n",
            "[21 22 23 24 25 26]\n",
            "window data\n",
            "[24 25 26 27 28 29]\n",
            "window data\n",
            "[27 28 29 30 31 32]\n",
            "window data\n",
            "[30 31 32 33 34 35]\n",
            "window data\n",
            "[33 34 35 36 37 38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLTIfpNH9Kys",
        "outputId": "817aba92-af8a-4780-ac0a-3258ae9eb92f"
      },
      "source": [
        "# splitting into features and labels\r\n",
        "# consider the first five as features and last one as the label\r\n",
        "dataset = tf.data.Dataset.range(40)\r\n",
        "dataset = dataset.window(6,shift=3, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda window : window.batch(6))\r\n",
        "# after creating the window batches use map to map the features and labels\r\n",
        "dataset =  dataset.map(lambda window: (window[:-1],window[-1:]))\r\n",
        "# printing out the data\r\n",
        "for x, y in dataset:\r\n",
        "  print(x.numpy(), y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4] [5]\n",
            "[3 4 5 6 7] [8]\n",
            "[ 6  7  8  9 10] [11]\n",
            "[ 9 10 11 12 13] [14]\n",
            "[12 13 14 15 16] [17]\n",
            "[15 16 17 18 19] [20]\n",
            "[18 19 20 21 22] [23]\n",
            "[21 22 23 24 25] [26]\n",
            "[24 25 26 27 28] [29]\n",
            "[27 28 29 30 31] [32]\n",
            "[30 31 32 33 34] [35]\n",
            "[33 34 35 36 37] [38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8vmpfUS-qQK",
        "outputId": "ab982f43-a2b5-49e8-aef1-9eafa92a95af"
      },
      "source": [
        "# the data often shuffled \r\n",
        "# can be done using .shuffle(buffer_size = n)  method\r\n",
        "dataset = tf.data.Dataset.range(40)\r\n",
        "dataset = dataset.window(6,shift=3, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda window : window.batch(6))\r\n",
        "dataset =  dataset.map(lambda window: (window[:-1],window[-1:]))\r\n",
        "# shuffling the values\r\n",
        "dataset = dataset.shuffle(buffer_size=10) # the buffer_size ?\r\n",
        "# printing out the data\r\n",
        "for x, y in dataset:\r\n",
        "  print(x.numpy(), y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 19 20 21 22] [23]\n",
            "[ 6  7  8  9 10] [11]\n",
            "[30 31 32 33 34] [35]\n",
            "[33 34 35 36 37] [38]\n",
            "[ 9 10 11 12 13] [14]\n",
            "[15 16 17 18 19] [20]\n",
            "[12 13 14 15 16] [17]\n",
            "[24 25 26 27 28] [29]\n",
            "[27 28 29 30 31] [32]\n",
            "[0 1 2 3 4] [5]\n",
            "[21 22 23 24 25] [26]\n",
            "[3 4 5 6 7] [8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4F2Dlnv_l4S",
        "outputId": "2f3cdfc6-b42c-4b66-cf8d-909caddffdba"
      },
      "source": [
        "# the data often load as batches\r\n",
        "# batches can be created by using batch() method\r\n",
        "dataset = tf.data.Dataset.range(40)\r\n",
        "dataset = dataset.window(6,shift=3, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda window : window.batch(6))\r\n",
        "dataset =  dataset.map(lambda window: (window[:-1],window[-1:]))\r\n",
        "# shuffling the values\r\n",
        "dataset = dataset.shuffle(buffer_size=40)\r\n",
        "# creating the batches\r\n",
        "dataset = dataset.batch(2).prefetch(1) # the value of prefetch ?\r\n",
        "# printing out the data\r\n",
        "for x, y in dataset:\r\n",
        "  print(\"x = \", x.numpy())\r\n",
        "  print(\"y = \", y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[24 25 26 27 28]\n",
            " [12 13 14 15 16]]\n",
            "y =  [[29]\n",
            " [17]]\n",
            "x =  [[0 1 2 3 4]\n",
            " [3 4 5 6 7]]\n",
            "y =  [[5]\n",
            " [8]]\n",
            "x =  [[18 19 20 21 22]\n",
            " [21 22 23 24 25]]\n",
            "y =  [[23]\n",
            " [26]]\n",
            "x =  [[33 34 35 36 37]\n",
            " [27 28 29 30 31]]\n",
            "y =  [[38]\n",
            " [32]]\n",
            "x =  [[30 31 32 33 34]\n",
            " [ 9 10 11 12 13]]\n",
            "y =  [[35]\n",
            " [14]]\n",
            "x =  [[15 16 17 18 19]\n",
            " [ 6  7  8  9 10]]\n",
            "y =  [[20]\n",
            " [11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNTct5nwAqqg"
      },
      "source": [
        "# function to return the windowed dataset\r\n",
        "def windowed_dataset(series, window_size,shift_size, batch_size,shuffle_buffer):\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\r\n",
        "  dataset = dataset.window(window_size +1, shift = shift_size, drop_remainder = True)\r\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\r\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window :  (window[:-1], window[-1]))\r\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\r\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_M7Y2U56CUc"
      },
      "source": [
        "def trend(time, slope=0):\r\n",
        "    return slope * time\r\n",
        "\r\n",
        "def seasonal_pattern(season_time):\r\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\r\n",
        "    return np.where(season_time < 0.4,\r\n",
        "                    np.cos(season_time * 2 * np.pi),\r\n",
        "                    1 / np.exp(3 * season_time))\r\n",
        "\r\n",
        "def seasonality(time, period, amplitude=1, phase=0):\r\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\r\n",
        "    season_time = ((time + phase) % period) / period\r\n",
        "    return amplitude * seasonal_pattern(season_time)\r\n",
        "\r\n",
        "def noise(time, noise_level=1, seed=None):\r\n",
        "    rnd = np.random.RandomState(seed)\r\n",
        "    return rnd.randn(len(time)) * noise_level\r\n",
        "\r\n",
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\r\n",
        "baseline = 10\r\n",
        "series = trend(time, 0.1)  \r\n",
        "baseline = 10\r\n",
        "amplitude = 40\r\n",
        "slope = 0.05\r\n",
        "noise_level = 5\r\n",
        "\r\n",
        "# Create the series\r\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\r\n",
        "# Update with noise\r\n",
        "series += noise(time, noise_level, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0-WKXG9Iob",
        "outputId": "8bca4b6d-fc86-44b6-ba07-8ac0a237ee15"
      },
      "source": [
        "series.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1461,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH8QOZbd9N6i",
        "outputId": "b1ecba18-28ad-41a3-84dc-48121ddb911c"
      },
      "source": [
        "type(series)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRkg-Jmw9nez",
        "outputId": "36aaa75a-ceec-43d6-f2f7-98af6125f598"
      },
      "source": [
        "time.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1461,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg2xGNGw9Ruq"
      },
      "source": [
        "# creating split for trining and testing\r\n",
        "split_time = 1000\r\n",
        "time_train = time[:split_time]\r\n",
        "x_train = series[:split_time]\r\n",
        "\r\n",
        "# for testing \r\n",
        "time_valid = time[split_time:]\r\n",
        "x_valid = series[split_time:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqquwxzc-CHZ"
      },
      "source": [
        "# creating the windowed data from series\r\n",
        "dataset = windowed_dataset(x_train, window_size=20, shift_size= 1, batch_size=32, shuffle_buffer=1000)\r\n",
        "# regression model\r\n",
        "# single dense layer \r\n",
        "L0 = tf.keras.layers.Dense(1,input_shape = [20])\r\n",
        "# defining the model \r\n",
        "model = tf.keras.models.Sequential([L0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hf04WCq_sEC",
        "outputId": "cbdcfcdd-ad2d-460e-f855-c1aab951de9e"
      },
      "source": [
        "# trining the model \r\n",
        "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9))\r\n",
        "model.fit(dataset,epochs=100,verbose=0)\r\n",
        "\r\n",
        "print(\"Layer weights {}\".format(L0.get_weights()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer weights [array([[-0.02214744],\n",
            "       [-0.07615466],\n",
            "       [ 0.10335191],\n",
            "       [-0.03430599],\n",
            "       [-0.00763742],\n",
            "       [ 0.08394616],\n",
            "       [ 0.00252062],\n",
            "       [-0.071883  ],\n",
            "       [ 0.00933745],\n",
            "       [ 0.00254631],\n",
            "       [-0.03578468],\n",
            "       [ 0.07111982],\n",
            "       [-0.06596499],\n",
            "       [-0.01594495],\n",
            "       [ 0.0995695 ],\n",
            "       [ 0.05201309],\n",
            "       [-0.00174174],\n",
            "       [ 0.14563236],\n",
            "       [ 0.34470424],\n",
            "       [ 0.39630368]], dtype=float32), array([0.0155364], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQD0sqy2Am03"
      },
      "source": [
        "# predicting the values\r\n",
        "test = x_valid[1:21][np.newaxis] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qZ0C7qV5A_C",
        "outputId": "f03a4751-7943-424a-b569-68cd1070abe0"
      },
      "source": [
        "print(type(test), test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (1, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClflUy0x5LjC",
        "outputId": "0274126c-6eca-49cb-fdd9-40d288301023"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[68.98552 , 64.6752  , 61.15736 , 67.89844 , 66.390305, 68.91469 ,\n",
              "        67.6307  , 69.71901 , 61.81174 , 71.091835, 65.51008 , 74.91588 ,\n",
              "        61.11138 , 73.25516 , 65.58317 , 61.35506 , 62.21152 , 63.048264,\n",
              "        66.79013 , 67.30303 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H90czJQ5PIa",
        "outputId": "ba7df604-d621-473f-fbdf-34b7fce7e340"
      },
      "source": [
        "model.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[65.02351]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bggfix0u5Wuq",
        "outputId": "4014f6f5-56d2-41b5-aa2a-1f1f63784d23"
      },
      "source": [
        "test = x_valid[21:41][np.newaxis] # newaxis is to deal with the imput size\r\n",
        "model.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[70.44973]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93duINRH5uwS",
        "outputId": "c1e44520-a5ac-4019-ab87-9cd8a53b1c40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPzvEWr56Ymi"
      },
      "source": [
        "forcast = []\r\n",
        "for time in range(len(x_train)- 20):\r\n",
        "  pass\r\n",
        "  # forcast.append(model.predict(x_train[]))\r\n",
        "  # todo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nyc-TG98wmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}